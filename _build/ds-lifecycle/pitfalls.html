---
title: |-
  Present-day Challenges in Data Science
pagenum: 3
prev_page:
  url: /ds-lifecycle/core.html
next_page:
  url: /ds-lifecycle/bias.html
suffix: .md
search: data us science neural networks field still years million scientists compared its computer significant challenges our few cleaning challenge accurate system obstacle huge allows precisely huffington post approximately world ancestors statistics booming remains increasing demand both market academia after much newer also seen motivate rethink refine techniques builds new tools overcome obstacles name nowadays where decade ago primary analysts facing today not dearth rather difficulty reducing large amount raw while retaining usefulness representation true population access perspective main analyzing summarizing dataset lies constantly accessing writing arent readily available hand memory section continuously improving hardware emergence distributed systems cloud get better

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Present-day Challenges in Data Science</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p>From Huffington Post in 2016</p>
<blockquote><p>There are approximately 1.5 [million] to 3 million data scientists in the world.</p>
</blockquote>
</blockquote>
<p>Compared to its ancestors statistics or computer science, data science is a booming field and still remains to see increasing demand from both the market and the academia years after years.</p>
<p>As a much newer field, data science has also seen significant challenges that motivate us to rethink and refine our techniques and builds new tools to overcome these obstacles.</p>
<p>To name a few, some of the most significant challenges in data science nowadays are:</p>
<ul>
<li><strong>Data Cleaning</strong>. Compared to where the field is a decade ago, the primary challenge data scientists/analysts are facing today is not the dearth of data, but rather <strong>the difficulty of cleaning and reducing the large amount of raw data while still retaining its usefulness and an accurate representation</strong> of the true population.</li>
<li><strong>Data Access</strong>. From a system perspective, the main obstacle of analyzing and summarizing a huge dataset lies in <strong>constantly accessing and writing the data</strong> (most of them aren't readily available to us at hand in the memory section of a computer). The continuously improving hardware and the emergence of distributed systems (<code>"the cloud"</code>) allows us to get better at solving this problem every year. Still, a huge responsibility and challenge for data engineers these days is to <strong>derive an algorithm/system that is as optimal as possible when working with retrieving and updating data from persistent storage</strong>.</li>
<li><strong>Data Modeling</strong>. Many of you have heard a lot in the past few years about breakthroughs in (deep) neural networks. As we will see in later sections of this book, although <strong>neural networks</strong> have grown to be a powerful technique that allows us to build accurate and robust models, the high compositeness and complexity embedded within the hidden layers of the networks have made it exponentially hard for us to actually <strong>understand precisely how each component of the neural network is contributing to the final prediction</strong>. This consequently introduces the obstacle: we don't know how to improve our neural networks model more precisely than through experimental design and testings (we lack a theoretical/mathematical basis).</li>
</ul>

</div>
</div>
</div>
</div>

 


    </main>
    