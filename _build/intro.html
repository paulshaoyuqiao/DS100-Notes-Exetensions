---
title: |-
  Home
pagenum: 0
prev_page:
  url: 
next_page:
  url: /ds-lifecycle/ds-lifecycle.html
suffix: .md
search: data analysis methods modeling learning regression component science course book linear clustering testing test notes extensions principles students sections provide means content summarizing sampling random variance method likelihood storage sql engineering basics update loss cross feature classification entropy vector unsupervised principle definiteness hi name paul shao currently lead ugsi uc berkeley upper div techniques compilation provided teaching discussion lab want short disclaimer substitute materials taught meant supplement additional perspectives wish explore around topics touched class structure divided into following overview lifecycle collection collecting extracting statistical simple population bootstrap web technologies text processing understanding normal approximation confidence intervals maximum estimates cleaning

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Home</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Data-100-Notes-&amp;-Extensions">Data 100 Notes &amp; Extensions<a class="anchor-link" href="#Data-100-Notes-&amp;-Extensions"> </a></h1><p>Hi! My name is Paul Shao, currently a lead uGSI at UC Berkeley for an upper-div data science course <strong>Principles &amp; Techniques of Data Science</strong> (<code>Data 100</code>). This book is a compilation of notes that I provided to my students when teaching discussion/lab sections for the course. I want to provide a short disclaimer that <strong>this book is by no means a substitute for the materials taught in Data 100</strong>, it is more meant supplement the course content and to provide some additional perspectives and extensions to students who wish to explore more around some of the topics touched on in class.</p>
<h2 id="Content-Structure">Content Structure<a class="anchor-link" href="#Content-Structure"> </a></h2><p>The book is divided into the following sections:</p>
<ul>
<li><strong>Overview</strong><ul>
<li>The Data Science Lifecycle</li>
</ul>
</li>
<li><strong>Data Collection</strong><ul>
<li>Collecting and Extracting Data<ul>
<li>Summarizing Data</li>
<li>Statistical Methods in Sampling</li>
<li>Simple Random Sampling</li>
<li>Population Variance and the Bootstrap Method</li>
<li>Web Technologies</li>
<li>Text Processing Methods</li>
</ul>
</li>
<li>Summarizing and Understanding Data<ul>
<li>Normal Approximation and Confidence Intervals</li>
<li>*Maximum Likelihood Estimates</li>
</ul>
</li>
</ul>
</li>
<li><strong>Data Cleaning</strong><ul>
<li>Core Structural Properties of Data</li>
</ul>
</li>
<li><strong>Exploratory Data Analysis (EDA)</strong><ul>
<li>Quantitative and Qualitative Data</li>
<li>Principles of Visualization</li>
<li>Plot Customization</li>
<li>Data Transformation</li>
</ul>
</li>
<li><strong>Data Storage and Pre-setup</strong><ul>
<li>Relational Database Systems</li>
<li>Single Table Queries in SQL</li>
<li>Joins</li>
<li>Subqueries</li>
<li>*Internals of an SQL Engine</li>
<li>*NoSQL and Cloud Storage</li>
</ul>
</li>
<li><strong>Data Engineering and Analysis</strong><ul>
<li><code>NumPy</code> Basics: Map, Filter, Reduce, and Update</li>
<li><code>Pandas</code> Basics: Retrieval, Search, and Update</li>
<li>Groupby, Aggregations</li>
<li>MultiIndex DataFrames</li>
</ul>
</li>
<li><strong>Data Modeling</strong>: Supervised Learning - Regression Methods<ul>
<li>Loss Functions</li>
<li>*Sparsity</li>
<li>Linear Regression</li>
<li>Features, Hyperparameters, and Cross-Validation</li>
<li>Bias-Variance Tradeoff</li>
<li>Residual Analysis</li>
<li>*Multivariate Gaussians</li>
<li>Feature Engineering</li>
<li>*Kernel Tricks and Feature Lifting</li>
<li>Regularization</li>
<li>Ridge Regression and LASSO</li>
<li>Nonlinear Least Squares and Gradient Descent</li>
<li>*Numerical Optimization Methods and Momentum</li>
</ul>
</li>
<li><strong>Data Modeling</strong>: Superivsed Learning - Classification Methods<ul>
<li>Evaluating Classifiers<ul>
<li>Confusion Matrix</li>
<li>ROC and PRC Curves</li>
</ul>
</li>
<li>Logistic Regression</li>
<li>Cross-Entropy Loss</li>
<li>Decision Trees</li>
<li>Entropy and Information Gain</li>
<li>Ensemble Method and Random Forest</li>
<li>Nearest Neighbor Classification</li>
<li>*Boosting</li>
<li>*Generating Better Linear Boundaries: Support Vector Machines (SVM)</li>
</ul>
</li>
<li><strong>Data Modeling</strong>: Unsupervised Learning - Principle Component Analysis<ul>
<li>Correlation and Covariance</li>
<li>Linear Independence, Vector Subspaces, and Change of Basis</li>
<li>Eigendecomposition and the Spectral Theorem</li>
<li>Singular Value Decomposition (SVD)</li>
<li>Positive Semi-Definiteness/Definiteness</li>
<li>Principle Component Analysis</li>
<li>*Indempotent Component Analysis</li>
<li>*Canonical Component Analysis</li>
</ul>
</li>
<li><strong>Data Modeling</strong>: Unsupervised Learning - Clustering<ul>
<li>K-Means Clustering</li>
<li>Other Clustering Methods</li>
<li>*Expectation-Maximization (EM) Algorithm</li>
<li>*Duality</li>
</ul>
</li>
<li><strong>Data Inference</strong><ul>
<li>Hypothesis Testing</li>
<li>Permutation Testing</li>
<li>P-values</li>
<li>Interval Estimation</li>
<li>Multiple Testing</li>
<li>*The Wald test and t-test</li>
<li>*The Likelihood Ratio Test</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
</div>

 


    </main>
    